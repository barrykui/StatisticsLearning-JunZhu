#### NB

moment parameter? canonical/natural?

指数的分布的一些很好的性质，哪些?

A distribution in the exponential family can be parameterized not only by     the canonical
parameterization, but also by     the moment parameterization.



$$\nabla_{\eta} A(\eta)=E(T(x))\\=\mu$$

#### Generalized Linear Models

$\mu$ is a represented by a response function $f(\xi)$, can be a smooth function.

mean parameter?

- choice of exp family
- choice of the response function

#### SGD and SGA difference?





#### IID Statistics and Random Sampling	

- **Identically Distributed** means that there are no overall trends–the distribution doesn’t fluctuate and all items in the sample are taken from the same probability distribution.
 - **Independent** means that the sample items are all independent events. In other words, they aren’t connected to each other in any way.		
  ​		

Plan for everyweek

#### Ensemble

model averaging, greedy methods partition function， overfitting

##### Tree

- binary split
- how to build a tree? gain? gain ratio? entropy 

Cons:

- not always good interpret
- error is carry forward to the ternimal node
- ​



##### Bagging

using boostrap strategy, to sampe

$C_1, C_2, C_3,…, C_n$, sure idencically dist,
$$
Var(\frac{1}{B}\sum{C_i})=\frac{1}{B}\sigma\\Corr(C_i, C_j)=\rho\\ Var(\frac{1}{B}\sum{C_i})=\rho\sigma+\frac{1-a}{R}\sigma)
$$
The structure is very similar, RF want to build a variant structure.

The distribution is 

##### Random Forests

random sample a subset, with $m$ features, 

##### Boosting

consider more error sample, iteratoin, change the distribution based on the error.

lots of boosting

The Frequently-used boosting method is AdaBoost.

AdaBoost is adding weight to a sample, any one who add adaboost into DNNs?

who?



#### Stagewise Additive Modeling 

residual learning? just like logistic Regression, ResNet?

current residuals:
$$
R=Y-\sum_{m=1}^{M-1}f_m(x)
$$
fit a tree to the residuals:
$$
min    E(R-f_M(x))^2
$$


builds an SDM by stagewise fitting using the loss function: 
$$
L(y,f(x))=exp(-yf(x)).
$$
SVM hinge loss, adaboost is a exp loss



feature is 

### Tasks

sigmoid的决策面?

SGD method is a stagewise additive modeling methods?

loss functions???

nn package,



ECCV ruhe? what's the topic 